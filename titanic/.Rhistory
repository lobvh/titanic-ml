install.packages("randomForest")
setwd("~/Desktop/git_projects/titanic-ml/titanic")
library(caret)
library(doSNOW)
library(rpart)
library(rpart.plot)
library(randomForest)
library(stringr)
#Get the data
train_data <- "train.csv"
test_data <- "test.csv"
#Load the data
train_set <- read.csv(train_data, header = TRUE) #We want the column names to be in the header, so header = TRUE
test_set <- read.csv(test_data, header = TRUE)
#Make combined dataset
survived <- rep("None", nrow(test_set))
test_set_with_survived <- data.frame(survived, test_set)
data_combined <- rbind(train_set, test_set_with_survived)
#Convert pclass and survived as pclass
data_combined$survived <- as.factor(data_combined$survived)
data_combined$pclass <- as.factor(data_combined$pclass)
####
#We will use whole dataset but different features for each Random Forest algorithm.
#Note that on combined dataset labels are "1" "0" and "None", where in train dataset we already have preprocessed ones and zeroes.
####
RF_LABELS <- as.factor(train_set$survived) #Made it upper-case since it's constant.
set.seed(2348)
cv_10_folds <- createMultiFolds(RF_LABELS, k = 10, times = 10)
# Set up caret's trainControl object per above.
ctrl_1 <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
index = cv_10_folds)
####
#Past titles
####
extractTitle <- function(name) {
name <- as.character(name)
if (length(grep("Miss.", name)) > 0) {
return ("Miss.")
} else if (length(grep("Master.", name)) > 0) {
return ("Master.")
} else if (length(grep("Mrs.", name)) > 0) {
return ("Mrs.")
} else if (length(grep("Mr.", name)) > 0) {
return ("Mr.")
} else {
return ("Other")
}
}
titles <- NULL
for (i in 1:nrow(data_combined)) {
titles <- c(titles, extractTitle(data_combined[i,"name"]))
}
data_combined$title <- as.factor(titles)
#####
#New Titles
#####
name.splits <- str_split(data_combined$name, ",")
name.splits <- str_split(sapply(name.splits, "[", 2), " ")
titles <- sapply(name.splits, "[", 2)
# Re-map titles to be more exact
titles[titles %in% c("Dona.", "the")] <- "Lady."
titles[titles %in% c("Ms.", "Mlle.")] <- "Miss."
titles[titles == "Mme."] <- "Mrs."
titles[titles %in% c("Jonkheer.", "Don.")] <- "Sir."
titles[titles %in% c("Col.", "Capt.", "Major.")] <- "Officer"
table(titles)
# Make title a factor
data_combined$new.title <- as.factor(titles)
####
#Collapse titles based on visual analysis
####
indexes <- which(data_combined$new.title == "Lady.")
data_combined$new.title[indexes] <- "Mrs."
indexes <- which(data_combined$new.title == "Dr." |
data_combined$new.title == "Rev." |
data_combined$new.title == "Sir." |
data_combined$new.title == "Officer")
data_combined$new.title[indexes] <- "Mr."
#####
#Ticket party size and Average fare feature
#####
ticket.party.size <- rep(0, nrow(data_combined))
avg.fare <- rep(0.0, nrow(data_combined))
tickets <- unique(data_combined$ticket)
for (i in 1:length(tickets)) {
current.ticket <- tickets[i]
party.indexes <- which(data_combined$ticket == current.ticket)
current.avg.fare <- data_combined[party.indexes[1], "fare"] / length(party.indexes)
for (k in 1:length(party.indexes)) {
ticket.party.size[party.indexes[k]] <- length(party.indexes)
avg.fare[party.indexes[k]] <- current.avg.fare
}
}
data_combined$ticket.party.size <- ticket.party.size
data_combined$avg.fare <- avg.fare
####
#Decision tree training function:
####
rpart.cv <- function(seed, training, labels, ctrl) {
cl <- makeCluster(6, type = "SOCK")
registerDoSNOW(cl)
set.seed(seed)
# Leverage formula interface for training
rpart.cv <- train(x = training, y = labels, method = "rpart", tuneLength = 30,
trControl = ctrl)
#Shutdown cluster
stopCluster(cl)
return (rpart.cv)
}
