#
#grep("Miss.", c("Miss. kelly", "dsddds")) --> 1
#grep("Miss.", "Miss. kelly") <=> grep("Miss.", c("Miss. kelly")) --> 1
#grep("Miss.", "krsds") --> 0
#Be aware of using Mrs. as first else if, and then Mr. because of the way grep() works!
#####
#Let's make a title vector and populate it with particular titles, based on row numbers:
titles <- NULL
for (i in 1:nrow(data_combined)) {
titles <- c(titles, extractTitle(data_combined[i,"name"]))
}
data_combined$title <- as.factor(titles)
#Here is one of the "whys" we use data_combined. If one finds out that title is "good" feature based on both datasets
#we can keep it and use it to train and test our ML model. If one finds out it's not good we can exclude it from both
#datasets using one command.
#Let's gather some facts using our freshly made feature:
ggplot(data_combined[1:891,], aes(x = title, fill = survived)) +
geom_bar() +
facet_wrap(~pclass) +
ggtitle("Pclass") +
xlab("Title") +
ylab("Total Count") +
labs(fill = "Survived")
######
#That higher class people had more chance of survival is confirmed this time.
#"Women and children first" holds the water too, especially in the first and second class.
#
#If one excludes everything except one title and see if there is any pattern, one would see that
#everything is quite skewed to the right.
#
#For example,if you just focus on Mr. title for three classes you will see that relative survival rate (based on the percent!)
#declines as we progress from first to third class. That same logic applies for each title.
#
#Title "Others" seem to be just in first two classes so might be indicative of folks (titles) who are rich.
#
#Mr.'s in second and third class have relative survival rate almost the same (around 1/8), those in first class have better survival rate!
#This is the thing with analysis: Even if Mr.'s in third class had lower rate of survival we should explain why, and see
#those who survived, can we see using other features (but be careful not to overfit!) to find a trend for survival of folks in third class.
#Fact (and hypothesis!?): Title would be a really good predictor of survival.
# - - - sex - - -
#####
# What's the distribution of females to males across train & test?
####
table(data_combined$sex)
#####
#Some things to point out is that data is skewed to the male spectrum, and if most of the males died and most of the
#females survived models tend to be in a favour of that. Males are more likely to perish than females so model could
#possibly deduce that "if you are a female you survive, if you are a male you are dead."
####
# Visualize the 3-way relationship of sex, pclass, and survival, compare to analysis of title
ggplot(data_combined[1:891,], aes(x = sex, fill = survived)) +
geom_bar() +
facet_wrap(~pclass) +
ggtitle("Pclass") +
xlab("Sex") +
ylab("Total Count") +
labs(fill = "Survived")
###
#One can see that as we go from the first class to the third there is a trend in females to survive far more likely than males.
#The odds in first and second class are far better than in the third class.
#But for the males that rate of survival is (so to say) dramatically decrease and that in percentage second and third class males
#have "same" survival rate. But as we saw from the title feature it gives us a better picture in who survives as a male or female.
###
# - - - age - - -
####
# From the analysis of 'title' variable (misses, mrses, males etc.) we infered that age and sex (as well as some other features!)
# seem pretty important, and that they might be correlated with title so we will take a closer look.
###
summary(data_combined$age)
###
#From the whole data_combined dataset (training+set) we see that there are a lot of NA's (around 20%!) and that is a lot of
# missing values. There are numerus ways one can handle missing data.
# For the ages one can for example impute missing ages with the (title etc.) mean or (title etc.) median.
# Or make a linear regression model using every other feature except age as an independent variable and age as dependent,
# make prediction's for the missing age and impute NA's with their predicted values, but keeping non-NA's as same.
# I've seen some authors say that if one put 0 as all NA's than for example neural network eventually learn that those are missing data.
# Probably each ones have different drawbacks.
#
# What we are gonna do here is run some "tests" to confirm that title could be a good proxy for age, so we are gonna forget about imputing missing values if we
# confirm that for each title it's age distribution relatively generalizes that title.
# And hopefully if we have "check" on each title, we are "safe" to ignore age and thus the imputation of it's missing values.
###
####
#Some conclusions that stick to my head using the summary on age on whole dataset is that people here are relatively young (one can define young however he choses!) .
# 75% of them are 40 and younger, and that 50% is less than 28.
# There are some outliers which could be justified or not based on other features.
# Mean is sliiiiiightly bigger than median which indicates sliiiiiiight skewnes to the right and thus sligghttt tendency
# toward the "bigger age".
# We once mentioned that the more the data is skewed towards something the more the tendency of an model is toward that skew.
####
summary(data_combined[1:891,"age"])
####
#One can also deduce that the training set has almost the same distribution for ages which indicates in order
#for age distribution on a complete dataset to remain same test set has to be similarly distributed as training set.
#Linear algebra trickery?
#I'm pointing this out because some authors say that it is good/ it saves the day (?) if your training and test data have similar distribution in terms of
# modeling. Or is it?
# Here is the summary for the training set:
summary(data_combined[891:1309, "age"])
# +
summary(data_combined[1:891,"age"])
# =
summary(data_combined$age)
# Just to be thorough, take a look at survival rates broken out by sex, pclass, and age
ggplot(data_combined[1:891,], aes(x = age, fill = survived)) +
facet_wrap(~sex + pclass) +
geom_histogram(binwidth = 10) +
xlab("Age") +
ylab("Total Count")
####
#We see in aggregate the confirmation that female tend to have better survival rates than men.
#For the females there is not so much of a pattern: class_1 vs class_2 they tend mostly to survive.
#For the class_3 younger ones tend to have better survival rate, and as we increase the number of age their chance of survival decreases.
#For the males, well class_1 has overall better survival rate than in class_2 and class_3.
#One can infer that younger pals have a good survival rate.
#Taking all this into aggregate (females survive better no matter the age + males who are younger tend to have better survival age)
#we can "confirm" our hypothesis "Women and children first" (all women including the younger ones and young males have good survival rate)
####
###
#Now we are gonna check if we can make 'title' as proxy for age!
###
# Validate that "Master." is a good proxy for male children
#First we gonna subset all the datapoints with title master...
boys <- data_combined[which(data_combined$title == "Master."),]
#... and take summary statistics:
summary(boys$age)
###
#Statistics are in favour of us and pretty much informative that yes, Master could be a good proxy for male children.
#Maximum age for the given distribution is 14.5, minimum is 0.33. 75% are less than 9 years old, so one can conclude
#that there were boys who are relatively young in age.
###
###
#Reflexively, if this is the distribution for "boys" then everything else in general would be "adult males".
#That's why we are not gonna subset Mr's, but let's take a quick summary to confirm it:
summary(data_combined[which(data_combined$title == "Mr."),]$age)
#In general there is a good separation between males of title Master. and Mr., and we are gonna show it
#using density plots:
#First we have to 'update' subset of males, since we added new feature 'title'
males_with_title <- data_combined[which(data_combined$sex == "male"),]
ggplot(males_with_title[males_with_title$title != "Other",], aes(x = age, fill = title)) +
geom_density(alpha = 0.5) +
xlab("Age") +
ylab("Total Count")
#One can see a decently clear separation between males of title Master. and Mr.
###
####
#We know that "Miss." is more complicated, let's examine further
#One can use the same variable name 'misses' in a sense of 'updating' existing variable and thus
#saving some memory. In order to be no confusion we will use different name for variable.
####
misses_updated <- data_combined[which(data_combined$title == "Miss."),]
mrses_updated <- data_combined[which(data_combined$title == "Mrs."),]
summary(misses_updated$age)
summary(mrses_updated$age)
###
#One can see that, yes, there is an 'obvious' separation between the titles of Miss-es and Mrs-es.
#As we observed previously Mrs-es are more "older" in general than Miss-es, but one should expect women that are not married passing some age!
#It's nothing unusual, one should've expect that.
#But the problem would be "how to distinguish female children vs adult non-maried Miss".
#We see that 25% of the Misses are 15 years or less, and it seems that the data is "skewed" which means that large portion of them are older/adult.
#Let's plot two density distributions for Miss-es and Mrs-es.
###
females <- data_combined[which(data_combined$sex == "female"),]
ggplot(females[females$title != "Other",], aes(x = age, fill = title)) +
geom_density(alpha = 0.5) +
xlab("Age") +
ylab("Total Count")
###
#As we expected, there is no clear separation between those two titles.
#One should expect that there are married women to be younger in age ('blue part in red part'),
#as well as that there are nonmarried women who are "older" in age.
#One could make many more inferencies from this density plot, but since this is iterative process I'm not gonna infer anything more.
#We see that we somehow need to 'extract children' both from Mrs-es and Miss-es.
#Let's see if other variables could help us with that!
###
####
#Sometimes I think that by understanding our data and feature engineering (aka making something explicit) we are helping not only ourselves,
#but also a ML model so it could make better predictions. Why is then data exploration so boring after all?!
####
###
#Enough for motivational messages. Let's see if pclass could help us better separate at least female children from Miss.
#After all, I forgot to mention that if the "child" is already married, it is no more child. It is an adult. Thats why we don't care for Mrs part of children.
####
ggplot(misses[misses$survived != "None",], aes(x = age, fill = survived)) +
facet_wrap(~pclass) +
geom_histogram(binwidth = 5) +
ggtitle("Age for 'Miss.' by Pclass") +
xlab("Age") +
ylab("Total Count")
####
#Mainly younger Misses (< or = 20 y.o) are from second and third class.
#Since we have title of Master that is at max 14.5y.o. we will generalize "female children" as so!
####
####
#One of the ways we can distinguish or so to say separate female children from the rest is by using heuristic:
#"Children don't travel alone, even at this day and age. Especially 18 or less."
#Let's sift and create misses_alone variable:
misses_alone <- misses_updated[which(misses_updated$sibsp == 0 & misses_updated$parch == 0),]
summary(misses_alone$age)
length(which(misses_alone$age <= 14.5))
#We see that 25% of them are 21y.o. or less, and the rest of them is relatively old!
#Since male children aka Master is assumed to be 14.5y.o. or less we will use same heuristic to distinguish female children.
#Since there is only 4 of them we can conclude that rest of the misses are children.
#We might be wrong, but not that wrong!
misses_rest <- misses_updated[which(misses_updated$sibsp != 0 & misses_updated$parch != 0),]
#We will use "helping-variable" in order to help us make density plot where we could separate misses_alone
#and misses_rest.
misses_ph <- rep("Alone", nrow(misses_alone))
misses_alone_1 <- data.frame(misses_alone, misses_ph)
misses_ph <- rep("Not Alone", nrow(misses_rest))
misses_rest_1 <- data.frame(misses_rest, misses_ph)
misses_updated_1 <- rbind(misses_alone_1, misses_rest_1)
ggplot(misses_updated_1, aes(x = age, fill = as.factor(misses_ph))) +
geom_density(alpha = 0.5) +
xlab("Age") +
ylab("Total Count") +
labs(fill = "Traveling:") +
ggtitle("Misses separation")
####
#If one focuses only on the part 20y.o. and less one can see that our misses_alone is a decent heuristic
#for separating younger women. Good proportion of graph indicates that there are many younger women who are not traveling alone!
#Yes, there are other misses who could travel with their friends etc. but I will stick to this.
###
# - - - sibsp - - -
#####
#Move on to the sibsp variable, summarize the variable
summary(data_combined$sibsp)
####
#One can see that median value is 0 which means that 50% of the passangers are traveling without sibling(s) or spouse
#that mean is so close to the mean which means (pun intended) tendency towards 0 and that the maximum value is 8.
#Nothing so special in my opinion, and can't conclude any meaningful stuff from this yet.
#Maybe we should treat it as a factor if there is a reasonable sense number of distinct values for sibsp.
#That would imensly help us to make some visualizations.
####
length(unique(data_combined$sibsp))
#7 is of a reasonable size so we will indeed treat it as factor.
data_combined$sibsp <- as.factor(data_combined$sibsp)
####
#From here we can make many graphs and get many different analysis of what seems resonable from an analysis perspective.
#One can make analysis relative to any or collection of features.
#I don't want to get into rabbit hole concluding that for example maybe it doesn't seem reasonable to look sibsp relative to name in terms of survival rate.
#Maybe it will help us to extract some features (combination of name and sibsp variable) in the future, but for now I will spare myself of that.
#I think for example that fare and sibsp have some good correlation and including both features would be redundant.
#Since title feature encompasses both sex and age maybe it makes more sense to watch it relative to that, and maybe segment it ("facet wrap it") relative to pclass.
ggplot(data_combined[1:891,], aes(x = sibsp, fill = survived)) +
geom_bar() +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("SibSp") +
ylab("Total Count") +
ylim(0,300) +
labs(fill = "Survived")
####
#There are predominantly people who travel with 0 or 1 sibsp. That's what summary on sibsp confirmed!
#Those who travel without sibling or spouse always have the best survival rate.
#Women and children first holds water here.
#Rich folks survived the most holds the water too.
#I don't see too much signal here. Might come back for revision!
####
####
#Not gonna get into too much detail of why it might be intuitive to treat parch as factor.
#At least for the sake of visualization it is possible to make some conclusions if parch is factor.
###
data_combined$parch <- as.factor(data_combined$parch)
ggplot(data_combined[1:891,], aes(x = parch, fill = survived)) +
geom_bar() +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("ParCh") +
ylab("Total Count") +
ylim(0,300) +
labs(fill = "Survived")
####
#If you switch in R between plots Pclass, Title vs Sibsp and Pclass, Title vs Parch you can intuit that
#graphs are pretty similar! I'm gonna argue (I keep switching between them while I'm typing this!) that
#survival rates for Mr. is the same in first class when sibs=0, but it's quite worse for the ones in second and third class
#even if data here is a bit skewed toward parch = 0.
#Speaking relatively to sibsp = 0 one can see that number of those who survived is the same in parch = 0,
#but those who perished is increased!
#Maybe someone can conclude something out of it.
#I might be wrong, but I think making model on parch will yield worse results for males than by using sibsp.
####
###
#But maybe if we combine them we will get a feature that is much more expresive!
#Combination of those we will call 'family-size'
###
temp_sibsp <- c(train_set$sibsp, test_set$sibsp) # Since we made
temp_parch <- c(train_set$parch, test_set$parch) #              these two to be factors, and now we need numbers!
data_combined$family_size <- as.factor(temp_sibsp + temp_parch + 1) #If parch and sibsp are factors...
####
#Again, won't argue too much why it might lead us astray to have some connections between name variable for example and new feature we engineered.
####
ggplot(data_combined[1:891,], aes(x = family_size, fill = survived)) +
geom_bar() +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("family.size") +
ylab("Total Count") +
ylim(0,300) +
labs(fill = "Survived")
###
#It's much informative in term of "survival trend" among the classes and titles, and maybe even obvious that
#if you have large family and it might be problem for you to keep everyone around, thus the chances of survival are bad.
###
# - - - ticket - - -
#####
#Just before we start I want to emphasise something called overfiting.
#I would be precise and say "overfiting on training data" since we are building our model based on training data.
#We could make a model that could be 100% precise, for example "if you are that and that name, you survive/perish" and build a model on top of that.
#On top of 'name' variables. When we imput some new data (test data) and there is no data with that name in the training set we are ruined.
#That is why we need a model that GENERALIZES on all training data. So when you see those graphs that map each data point precisely, that is the sign of overfitting.
#####
####
#On to the ticket variable. As Dave pointed out, one should get used to write str() for each variable whenever we start analyzing it.
#It's a shorthand for using str() on a combined dataset.
####
str(data_combined$ticket)
####
#Based on the huge number of levels ticket really isn't a factor variable it is a string, so let's convert it.
#Then we will show first 50 of them. We could use 'any number'. It's for a sake of giving us a bigger picture aka we will better see pattern
#if there are relatively high number of data points, especially for this kind of variable.
####
data_combined$ticket <- as.character(data_combined$ticket)
data_combined$ticket[1:50]
####
#There's no immediately apparent structure in the data, let's see if we can find some. I saw on the internet that those indicate something but won't delve deep into that.
#We'll start with taking a look at just the first char for each.
#It's easy for visualization if there are relatively few (we can make them as factor!)
#It's not necessarily correct way of extracting feature, or that one should expect something out of it.
#This is some 'basic heuristic'.
####
ticket_first_char <- ifelse(data_combined$ticket == "", " ", substr(data_combined$ticket,1,1))
unique(ticket_first_char)
####
#OK, we can make a factor for analysis purposes and visualize
###
data_combined$ticket_first_char <- as.factor(ticket_first_char)
# First, a high-level plot of the data
ggplot(data_combined[1:891,], aes(x = ticket_first_char, fill = survived)) +
geom_bar() +
ggtitle("Survivability by ticket.first.char") +
xlab("ticket.first.char") +
ylab("Total Count") +
ylim(0,350) +
labs(fill = "Survived")
####
#One might conclude from the plot that since we know that those tickets that start with 1, 2 and 3 might be indicators of pclass.
#But there are more people in first class that in second:
table(data_combined$pclass)
#Maybe those from 4, 5, etc. could be also grouped into first, second and third class in order to confirm previous hypothesis?
#It's quite a mixed bag of survivability, and we hate overfiting... Might be predictive, but let's drill a bit more!
####
ggplot(data_combined[1:891,], aes(x = ticket_first_char, fill = survived)) +
geom_bar() +
facet_wrap(~pclass) +
ggtitle("Pclass") +
xlab("ticket.first.char") +
ylab("Total Count") +
ylim(0,300) +
labs(fill = "Survived")
###
#We can see that majority tickets in each class start with the same number as pclass they are in.
#If we put that stack of P on top of 1 in the first class we will have "that amount of people" which
#further implies that our previous hypothesis is true! That majority of imbalance for first class is "hidding" in the P?
#There is W in each class, and very few of them. Might indicate some kind of people that are indeed passengers, but maybe some workers or something?
#There might be some signal here, but I will keep it in back of my head.
###
####
# Lastly, see if we get a pattern when using combination of pclass & title
###
ggplot(data_combined[1:891,], aes(x = ticket_first_char, fill = survived)) +
geom_bar() +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("ticket.first.char") +
ylab("Total Count") +
ylim(0,200) +
labs(fill = "Survived")
###
#Again, this is based just on a frist letter of ticket. Everything matches with our intuition about survivability, but I don't
#see some patterns that stick out here. Maybe thorough investigation of ticket feature will be more fruitful.
###
# - - - fare - - -
####
#Next up - the fares Titanic passengers paid
####
str(data_combined$fare)
summary(data_combined$fare)
length(unique(data_combined$fare))
###
#We can't make it a factor... Too much instances.
# Can't make fare a factor, treat as numeric & visualize with histogram
ggplot(data_combined, aes(x = fare)) +
geom_histogram(binwidth = 5) +
ggtitle("Combined Fare Distribution") +
xlab("Fare") +
ylab("Total Count") +
ylim(0,200)
# Let's check to see if fare has predictive power
ggplot(data_combined[1:891,], aes(x = fare, fill = survived)) +
geom_histogram(binwidth = 5) +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("fare") +
ylab("Total Count") +
ylim(0,50) +
labs(fill = "Survived")
ggplot(data_combined, aes(x = fare)) +
geom_histogram(binwidth = 5) +
ggtitle("Combined Fare Distribution") +
xlab("Fare") +
ylab("Total Count") +
ylim(0,200)
summary(data_combined$fare)
library(randomForest)
rf_train_1 <- data_combined[1:891, c("pclass", "title")]
RF_LABELS <- as.factor(train[1:891,"survived"])
RF_LABELS <- as.factor(train$survived)
RF_LABELS <- as.factor(train_set$survived)
RF_LABELS <- as.factor(train_set$survived) #Made it upper-case since it's constant.
set.seed(1234)
rf_train_1 <- data_combined[1:891, c("pclass", "title")]
set.seed(1234)
random_forest_1 <- randomForest(x = rf_train_1, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_1
varImpPlot(random_forest_1)
13/536
168/174
174/536
536+168
704/891
536/891
13/891
168*0.5
random_forest_1
174/891
168+174
174/342
rf_train_2 <- data_combined[1:891, c("pclass", "title", "sibsp")]
set.seed(1234)
random_forest_2 <- randomForest(x = rf.train.2, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_2
varImpPlot(random_forest_2)
rf_train_2 <- data_combined[1:891, c("pclass", "title", "sibsp")]
set.seed(1234)
random_forest_2 <- randomForest(x = rf.train.2, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_2
varImpPlot(random_forest_2)
rf_train_2 <- data_combined[1:891, c("pclass", "title", "sibsp")]
set.seed(1234)
random_forest_2 <- randomForest(x = rf_train_2, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_2
varImpPlot(random_forest_2)
random_forest_1
rf_train_3 <- data.combined[1:891, c("pclass", "title", "parch")]
set.seed(1234)
random_forest_3 <- randomForest(x = rf_train_3, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_3
varImpPlot(random_forest_3)
rf_train_3 <- data.combined[1:891, c("pclass", "title", "parch")]
rf_train_3 <- data_combined[1:891, c("pclass", "title", "parch")]
set.seed(1234)
random_forest_3 <- randomForest(x = rf_train_3, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_3
varImpPlot(random_forest_3)
random_forest_2
random_forest_3
rf_train_4 <- data_combined[1:891, c("pclass", "title", "sibsp", "parch")]
set.seed(1234)
random_forest_4 <- randomForest(x = rf_train_4, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_4
varImpPlot(random_forest_4)
490+231
721/891
1-0.8092031
random_forest_4$err.rate
random_forest_4
random_forest_4
rf_train_5 <- data.combined[1:891, c("pclass", "title", "family_size")]
set.seed(1234)
random_forest_5 <- randomForest(x = rf_train_5, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_5
varImpPlot(random_forest_5)
random_forest_4
rf_train_5 <- data_combined[1:891, c("pclass", "title", "family_size")]
set.seed(1234)
random_forest_5 <- randomForest(x = rf_train_5, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_5
varImpPlot(random_forest_5)
rf_train_6 <- data_combined[1:891, c("pclass", "title", "sibsp", "family_size")]
set.seed(1234)
random_forest_6 <- randomForest(x = rf_train_6, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_6
varImpPlot(random_forest_6)
rf_train_7 <- data_combined[1:891, c("pclass", "title", "parch", "family_size")]
set.seed(1234)
random_forest_7 <- randomForest(x = rf_train_7, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_7
varImpPlot(random_forest_7)
rf_train_8 <- data_combined[1:891, c("pclass", "title", "sibsp", "parch", "family_size")]
set.seed(1234)
random_forest_8 <- randomForest(x = rf_train_8, y = RF_LABELS, importance = TRUE, ntree = 1000)
random_forest_8
varImpPlot(random_forest_8)
random_forest_1
random_forest_2
random_forest_3
random_forest_4
random_forest_5
random_forest_6
random_forest_7
random_forest_8
