#Let's see if other variables could help us with that!
###
####
#Sometimes I think that by understanding our data and feature engineering (aka making something explicit) we are helping not only ourselves,
#but also a ML model so it could make better predictions. Why is then data exploration so boring after all?!
####
###
#Enough for motivational messages. Let's see if pclass could help us better separate at least female children from Miss.
#After all, I forgot to mention that if the "child" is already married, it is no more child. It is an adult. Thats why we don't care for Mrs part of children.
####
ggplot(misses[misses$survived != "None",], aes(x = age, fill = survived)) +
facet_wrap(~pclass) +
geom_histogram(binwidth = 5) +
ggtitle("Age for 'Miss.' by Pclass") +
xlab("Age") +
ylab("Total Count")
####
#Mainly younger Misses (< or = 20 y.o) are from second and third class.
#Since we have title of Master that is at max 14.5y.o. we will generalize "female children" as so!
####
####
#One of the ways we can distinguish or so to say separate female children from the rest is by using heuristic:
#"Children don't travel alone, even at this day and age. Especially 18 or less."
#Let's sift and create misses_alone variable:
misses_alone <- misses_updated[which(misses_updated$sibsp == 0 & misses_updated$parch == 0),]
summary(misses_alone$age)
length(which(misses_alone$age <= 14.5))
#We see that 25% of them are 21y.o. or less, and the rest of them is relatively old!
#Since male children aka Master is assumed to be 14.5y.o. or less we will use same heuristic to distinguish female children.
#Since there is only 4 of them we can conclude that rest of the misses are children.
#We might be wrong, but not that wrong!
misses_rest <- misses_updated[which(misses_updated$sibsp != 0 & misses_updated$parch != 0),]
#We will use "helping-variable" in order to help us make density plot where we could separate misses_alone
#and misses_rest.
misses_ph <- rep("Alone", nrow(misses_alone))
misses_alone_1 <- data.frame(misses_alone, misses_ph)
misses_ph <- rep("Not Alone", nrow(misses_rest))
misses_rest_1 <- data.frame(misses_rest, misses_ph)
misses_updated_1 <- rbind(misses_alone_1, misses_rest_1)
ggplot(misses_updated_1, aes(x = age, fill = as.factor(misses_ph))) +
geom_density(alpha = 0.5) +
xlab("Age") +
ylab("Total Count") +
labs(fill = "Traveling:") +
ggtitle("Misses separation")
####
#If one focuses only on the part 20y.o. and less one can see that our misses_alone is a decent heuristic
#for separating younger women. Good proportion of graph indicates that there are many younger women who are not traveling alone!
#Yes, there are other misses who could travel with their friends etc. but I will stick to this.
###
# - - - sibsp - - -
#####
#Move on to the sibsp variable, summarize the variable
summary(data_combined$sibsp)
####
#One can see that median value is 0 which means that 50% of the passangers are traveling without sibling(s) or spouse
#that mean is so close to the mean which means (pun intended) tendency towards 0 and that the maximum value is 8.
#Nothing so special in my opinion, and can't conclude any meaningful stuff from this yet.
#Maybe we should treat it as a factor if there is a reasonable sense number of distinct values for sibsp.
#That would imensly help us to make some visualizations.
####
length(unique(data_combined$sibsp))
#7 is of a reasonable size so we will indeed treat it as factor.
data_combined$sibsp <- as.factor(data_combined$sibsp)
####
#From here we can make many graphs and get many different analysis of what seems resonable from an analysis perspective.
#One can make analysis relative to any or collection of features.
#I don't want to get into rabbit hole concluding that for example maybe it doesn't seem reasonable to look sibsp relative to name in terms of survival rate.
#Maybe it will help us to extract some features (combination of name and sibsp variable) in the future, but for now I will spare myself of that.
#I think for example that fare and sibsp have some good correlation and including both features would be redundant.
#Since title feature encompasses both sex and age maybe it makes more sense to watch it relative to that, and maybe segment it ("facet wrap it") relative to pclass.
ggplot(data_combined[1:891,], aes(x = sibsp, fill = survived)) +
geom_bar() +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("SibSp") +
ylab("Total Count") +
ylim(0,300) +
labs(fill = "Survived")
####
#There are predominantly people who travel with 0 or 1 sibsp. That's what summary on sibsp confirmed!
#Those who travel without sibling or spouse always have the best survival rate.
#Women and children first holds water here.
#Rich folks survived the most holds the water too.
#I don't see too much signal here. Might come back for revision!
####
####
#Not gonna get into too much detail of why it might be intuitive to treat parch as factor.
#At least for the sake of visualization it is possible to make some conclusions if parch is factor.
###
data_combined$parch <- as.factor(data_combined$parch)
ggplot(data_combined[1:891,], aes(x = parch, fill = survived)) +
geom_bar() +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("ParCh") +
ylab("Total Count") +
ylim(0,300) +
labs(fill = "Survived")
####
#If you switch in R between plots Pclass, Title vs Sibsp and Pclass, Title vs Parch you can intuit that
#graphs are pretty similar! I'm gonna argue (I keep switching between them while I'm typing this!) that
#survival rates for Mr. is the same in first class when sibs=0, but it's quite worse for the ones in second and third class
#even if data here is a bit skewed toward parch = 0.
#Speaking relatively to sibsp = 0 one can see that number of those who survived is the same in parch = 0,
#but those who perished is increased!
#Maybe someone can conclude something out of it.
#I might be wrong, but I think making model on parch will yield worse results for males than by using sibsp.
####
###
#But maybe if we combine them we will get a feature that is much more expresive!
#Combination of those we will call 'family-size'
###
temp_sibsp <- c(train_set$sibsp, test_set$sibsp) # Since we made
temp_parch <- c(train_set$parch, test_set$parch) #              these two to be factors, and now we need numbers!
data_combined$family_size <- as.factor(temp_sibsp + temp_parch + 1) #If parch and sibsp are factors...
####
#Again, won't argue too much why it might lead us astray to have some connections between name variable for example and new feature we engineered.
####
ggplot(data_combined[1:891,], aes(x = family_size, fill = survived)) +
geom_bar() +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("family.size") +
ylab("Total Count") +
ylim(0,300) +
labs(fill = "Survived")
###
#It's much informative in term of "survival trend" among the classes and titles, and maybe even obvious that
#if you have large family and it might be problem for you to keep everyone around, thus the chances of survival are bad.
###
# - - - ticket - - -
#####
#Just before we start I want to emphasise something called overfiting.
#I would be precise and say "overfiting on training data" since we are building our model based on training data.
#We could make a model that could be 100% precise, for example "if you are that and that name, you survive/perish" and build a model on top of that.
#On top of 'name' variables. When we imput some new data (test data) and there is no data with that name in the training set we are ruined.
#That is why we need a model that GENERALIZES on all training data. So when you see those graphs that map each data point precisely, that is the sign of overfitting.
#####
####
#On to the ticket variable. As Dave pointed out, one should get used to write str() for each variable whenever we start analyzing it.
#It's a shorthand for using str() on a combined dataset.
####
str(data_combined$ticket)
####
#Based on the huge number of levels ticket really isn't a factor variable it is a string, so let's convert it.
#Then we will show first 50 of them. We could use 'any number'. It's for a sake of giving us a bigger picture aka we will better see pattern
#if there are relatively high number of data points, especially for this kind of variable.
####
data_combined$ticket <- as.character(data_combined$ticket)
data_combined$ticket[1:50]
####
#There's no immediately apparent structure in the data, let's see if we can find some. I saw on the internet that those indicate something but won't delve deep into that.
#We'll start with taking a look at just the first char for each.
#It's easy for visualization if there are relatively few (we can make them as factor!)
#It's not necessarily correct way of extracting feature, or that one should expect something out of it.
#This is some 'basic heuristic'.
####
ticket_first_char <- ifelse(data_combined$ticket == "", " ", substr(data_combined$ticket,1,1))
unique(ticket_first_char)
####
#OK, we can make a factor for analysis purposes and visualize
###
data_combined$ticket_first_char <- as.factor(ticket_first_char)
# First, a high-level plot of the data
ggplot(data_combined[1:891,], aes(x = ticket_first_char, fill = survived)) +
geom_bar() +
ggtitle("Survivability by ticket.first.char") +
xlab("ticket.first.char") +
ylab("Total Count") +
ylim(0,350) +
labs(fill = "Survived")
####
#One might conclude from the plot that since we know that those tickets that start with 1, 2 and 3 might be indicators of pclass.
#But there are more people in first class that in second:
table(data_combined$pclass)
#Maybe those from 4, 5, etc. could be also grouped into first, second and third class in order to confirm previous hypothesis?
#It's quite a mixed bag of survivability, and we hate overfiting... Might be predictive, but let's drill a bit more!
####
ggplot(data_combined[1:891,], aes(x = ticket_first_char, fill = survived)) +
geom_bar() +
facet_wrap(~pclass) +
ggtitle("Pclass") +
xlab("ticket.first.char") +
ylab("Total Count") +
ylim(0,300) +
labs(fill = "Survived")
###
#We can see that majority tickets in each class start with the same number as pclass they are in.
#If we put that stack of P on top of 1 in the first class we will have "that amount of people" which
#further implies that our previous hypothesis is true! That majority of imbalance for first class is "hidding" in the P?
#There is W in each class, and very few of them. Might indicate some kind of people that are indeed passengers, but maybe some workers or something?
#There might be some signal here, but I will keep it in back of my head.
###
####
# Lastly, see if we get a pattern when using combination of pclass & title
###
ggplot(data_combined[1:891,], aes(x = ticket_first_char, fill = survived)) +
geom_bar() +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("ticket.first.char") +
ylab("Total Count") +
ylim(0,200) +
labs(fill = "Survived")
###
#Again, this is based just on a frist letter of ticket. Everything matches with our intuition about survivability, but I don't
#see some patterns that stick out here. Maybe thorough investigation of ticket feature will be more fruitful.
###
# - - - fare - - -
####
#Next up - the fares Titanic passengers paid
####
str(data_combined$fare)
summary(data_combined$fare)
length(unique(data_combined$fare))
###
#We can't make it a factor... Too much instances.
###
###High level overview
ggplot(data_combined, aes(x = fare)) +
geom_histogram(binwidth = 5) +
ggtitle("Combined Fare Distribution") +
xlab("Fare") +
ylab("Total Count") +
ylim(0,200)
####
#There are some folks that haven't paid anything? That could be interesting.
#We see that distribution is skewed towards higher end. We should expect that, because majority of folks that were on Titanic were in third class.
#aka low fares. We confirmed that with median<mean, and also median = 14.454.
#There is an outlier up there where fare>500, but further investigation of fare variable will tell us why is that so.
###
####
#Now that we have high level overview, let's see if it's predictive in some sense:
####
ggplot(data_combined[1:891,], aes(x = fare, fill = survived)) +
geom_histogram(binwidth = 5) +
facet_wrap(~pclass + title) +
ggtitle("Pclass, Title") +
xlab("fare") +
ylab("Total Count") +
ylim(0,50) +
labs(fill = "Survived")
####
#One would expect that rich folks survived more, and indeed that is so. I don't see anything that will cause more than overfitting here, because
#everytihing matches our previous intuitions in terms of survivability. I will leave fare for now, but it might help me to feature engineer something using it.
####
################################################################################################
#                               EXPLANATORY DATA ANALYSIS                                      #
################################################################################################
####
#
#This is the part where we check our intuitions about features, and also test if our feature engineering is worthwhile.
#I think "all" of the ML algos have explicit or implicit way of providing us with the feature importance.
#We need something that is fast (for classification problems!), effective and simple to interpret.
#Without worrying too much on hyperparameters. We will leave that fine tuning for the "real" modeling part.
#
#
#We will use Random Forests here. I wont drill about the algorithm here there is plenty of it on Internet.
#In an essence it uses ensemble method of trees and averages loss on each tree.
#Each tree gets it bootstraped sample (drawing N samples from training set where N is number of rows in training set).
#By drawing samples with replacement some of the rows won't be sampled. Those are colled out-of-bag.
#Evaluate model on samples that you drawed, test the model on non-sampled (out-of-bag) ones.
#What confuses most people is when you are evaluating loss on that particular tree OOB sample is HIDDING it's labels.
#You get the predicted ones, then you compare it with the real labels and calculate loss.
#Draw samples -> Make model (tree) on them -> Test the model (tree) on OOB by hiding it's labels -> Compare real labels of OOB with predicted ones -> Calculate loss
#Then you repeat that proces for each tree and compute the average loss.
#Now watch out, since you are drawing samples RANDOMLY with replacement some of the OOB's from the first tree won't be OOB on some other trees.
#That's why validation on test data is way more accurate of overall accuracy than OOB since each data point from test set has been put
#through EACH TREE in Random Forest, where some of the OOB samples are not tested on all trees.
#There is also (I guess!) a high probability that EACH training sample will be picked in some of the OOB's at least once, so that's why in confusion matrix you will get score for each row.
#
#That's a high-overview enough to get you started. I'm not an expert on RF's...
#
####
###
#Let's import the randomForest library.
###
library(randomForest)
####
RF_LABELS <- as.factor(train_set$survived) #Made it upper-case since it's constant.
library(caret)
library(doSNOW)
set.seed(37596)
cv_3_folds <- createMultiFolds(RF_LABELS, k = 3, times = 10)
ctrl_3 <- trainControl(method = "repeatedcv", number = 3, repeats = 10,
index = cv_3_folds)
####
#Parse out last name and title:
#Based on how 'name' variable look we need to find a way to extract the title variable properly.
####
data_combined[1:25, "name"]
name.splits <- str_split(data_combined$name, ",")
name.splits[1]
####
#This might be a nice place to extract last name title, which might be used later.
####
last.names <- sapply(name.splits, "[", 1)
last.names[1:10]
data.combined$last.name <- last.names
####
#Here we are gonna extract titles.
####
name.splits <- str_split(sapply(name.splits, "[", 2), " ")
titles <- sapply(name.splits, "[", 2)
unique(titles)
####
#We see that some of the 'new' titles we havent seen might be indicative of nobility, and hence people who are rich.
#Using the experience of Google you can get the idea of why one would aggregate these variables as such:
####
# What's up with a title of 'the'?
data_combined[which(titles == "the"),]
# Re-map titles to be more exact
titles[titles %in% c("Dona.", "the")] <- "Lady."
titles[titles %in% c("Ms.", "Mlle.")] <- "Miss."
titles[titles == "Mme."] <- "Mrs."
titles[titles %in% c("Jonkheer.", "Don.")] <- "Sir."
titles[titles %in% c("Col.", "Capt.", "Major.")] <- "Officer"
table(titles)
# Make title a factor
data_combined$new.title <- as.factor(titles)
# Visualize new version of title
ggplot(data_combined[1:891,], aes(x = new.title, fill = survived)) +
geom_bar() +
facet_wrap(~ pclass) +
ggtitle("Surival Rates for new.title by pclass")
####
#We see that yeah, these folks wiht title of Dr. etc. are more correlated with those that are in higher classes.
#We have already decided that Ms, Mile are Miss, and Mme. is Mr.
#From this plot based on relative survival rate we can put into the same basket other
#nobility titles.
# Collapse titles based on visual analysis
indexes <- which(data.combined$new.title == "Lady.")
data_combined$new.title[indexes] <- "Mrs."
indexes <- which(data_combined$new.title == "Dr." |
data_combined$new.title == "Rev." |
data_combined$new.title == "Sir." |
data_combined$new.title == "Officer")
data_combined$new.title[indexes] <- "Mr."
ggplot(data.combined[1:891,], aes(x = new.title, fill = survived)) +
geom_bar() +
facet_wrap(~ pclass) +
ggtitle("Surival Rates for Collapsed new.title by pclass")
ggplot(data_combined[1:891,], aes(x = new.title, fill = survived)) +
geom_bar() +
facet_wrap(~ pclass) +
ggtitle("Surival Rates for Collapsed new.title by pclass")
indexes <- which(data.combined$new.title == "Lady.")
data_combined$new.title[indexes] <- "Mrs."
indexes <- which(data_combined$new.title == "Dr." |
data_combined$new.title == "Rev." |
data_combined$new.title == "Sir." |
data_combined$new.title == "Officer")
data_combined$new.title[indexes] <- "Mr."
#####
#Visualize the final result to check if everything is correct:
#####
ggplot(data_combined[1:891,], aes(x = new.title, fill = survived)) +
geom_bar() +
facet_wrap(~ pclass) +
ggtitle("Surival Rates for Collapsed new.title by pclass")
titles[titles %in% c("Dona.", "the")] <- "Lady."
titles[titles %in% c("Ms.", "Mlle.")] <- "Miss."
titles[titles == "Mme."] <- "Mrs."
titles[titles %in% c("Jonkheer.", "Don.")] <- "Sir."
titles[titles %in% c("Col.", "Capt.", "Major.")] <- "Officer"
table(titles)
data_combined$new.title <- as.factor(titles)
# Visualize new version of title
ggplot(data_combined[1:891,], aes(x = new.title, fill = survived)) +
geom_bar() +
facet_wrap(~ pclass) +
ggtitle("Surival Rates for new.title by pclass")
####
#We see that yeah, these folks wiht title of Dr. etc. are more correlated with those that are in higher classes.
#We have already decided that Ms, Mile are Miss, and Mme. is Mr.
#From this plot, based on relative survival rate, we can put into the same basket other
#nobility titles.
####
#Collapse titles based on visual analysis
####
indexes <- which(data.combined$new.title == "Lady.")
data_combined$new.title[indexes] <- "Mrs."
indexes <- which(data_combined$new.title == "Dr." |
data_combined$new.title == "Rev." |
data_combined$new.title == "Sir." |
data_combined$new.title == "Officer")
data_combined$new.title[indexes] <- "Mr."
ggplot(data_combined[1:891,], aes(x = new.title, fill = survived)) +
geom_bar() +
facet_wrap(~ pclass) +
ggtitle("Surival Rates for Collapsed new.title by pclass")
####
#Collapse titles based on visual analysis
####
indexes <- which(data_combined$new.title == "Lady.")
ggplot(data_combined[1:891,], aes(x = new.title, fill = survived)) +
geom_bar() +
facet_wrap(~ pclass) +
ggtitle("Surival Rates for Collapsed new.title by pclass")
indexes <- which(data_combined$new.title == "Lady.")
data_combined$new.title[indexes] <- "Mrs."
ggplot(data_combined[1:891,], aes(x = new.title, fill = survived)) +
geom_bar() +
facet_wrap(~ pclass) +
ggtitle("Surival Rates for Collapsed new.title by pclass")
features <- c("pclass", "new.title", "family_size")
rpart.train.2 <- data_combined[1:891, features]
# Run CV and check out results
rpart.2.cv.1 <- rpart.cv(94622, rpart.train.2, rf.label, ctrl.3)
rpart.2.cv.1
rpart.cv <- function(seed, training, labels, ctrl) {
cl <- makeCluster(6, type = "SOCK")
registerDoSNOW(cl)
set.seed(seed)
# Leverage formula interface for training
rpart.cv <- train(x = training, y = labels, method = "rpart", tuneLength = 30,
trControl = ctrl)
#Shutdown cluster
stopCluster(cl)
return (rpart.cv)
}
rpart.2.cv.1 <- rpart.cv(94622, rpart.train.2, rf.label, ctrl.3)
rpart.2.cv.1
# Run CV and check out results
rpart.2.cv.1 <- rpart.cv(94622, rpart.train.2, RF_LABELS, ctrl_3)
rpart.2.cv.1
# Plot
prp(rpart.2.cv.1$finalModel, type = 0, extra = 1, under = TRUE)
library(rpart)
library(rpart.plot)
# Plot
prp(rpart.2.cv.1$finalModel, type = 0, extra = 1, under = TRUE)
####
#Let's plot the decision tree:
####
prp(rpart.1.cv.1$finalModel, type = 0, extra = 1, under = TRUE)
rpart.1.cv.1 <- rpart.cv(94622, rpart.train.1, RF_LABELS, ctrl_3)
rpart.1.cv.1
####
#We obtained the accuracy of 0.8210999 on this model.
#Compared to random forest model with the same parameters (0.8139169) we are better. But this is expected, since we are training decision tree.
####
#Let's plot the decision tree:
####
prp(rpart.1.cv.1$finalModel, type = 0, extra = 1, under = TRUE)
features <- c("pclass", "title", "family_size")
rpart.train.1 <- data_combined[1:891, features]
# Run CV and check out results
rpart.1.cv.1 <- rpart.cv(94622, rpart.train.1, RF_LABELS, ctrl_3)
rpart.1.cv.1
####
#We obtained the accuracy of 0.8210999 on this model.
#Compared to random forest model with the same parameters (0.8139169) we are better. But this is expected, since we are training decision tree.
####
#Let's plot the decision tree:
####
prp(rpart.1.cv.1$finalModel, type = 0, extra = 1, under = TRUE)
indexes.first.mr <- which(data_combined$new.title == "Mr." & data_combined$pclass == "1")
first.mr.df <- data_combined[indexes.first.mr, ]
summary(first.mr.df)
####
#One female? Let's check that out.
####
first.mr.df[first.mr.df$sex == "female",]
# Update new.title feature
indexes <- which(data_combined$new.title == "Mr." &
data_combined$sex == "female")
data_combined$new.title[indexes] <- "Mrs."
# Any other gender slip-ups?
length(which(data_combined$sex == "female" &
(data_combined$new.title == "Master." |
data_combined$new.title == "Mr.")))
# Refresh data frame
indexes.first.mr <- which(data_combined$new.title == "Mr." & data_combined$pclass == "1")
first.mr.df <- data_combined[indexes.first.mr, ]
# Let's look at surviving 1st class "Mr."
summary(first.mr.df[first.mr.df$survived == "1",])
View(first.mr.df[first.mr.df$survived == "1",])
# Take a look at some of the high fares
indexes <- which(data_combined$ticket == "PC 17755" |
data_combined$ticket == "PC 17611" |
data_combined$ticket == "113760")
View(data_combined[indexes,])
# Visualize survival rates for 1st class "Mr." by fare
ggplot(first.mr.df, aes(x = fare, fill = survived)) +
geom_density(alpha = 0.5) +
ggtitle("1st Class 'Mr.' Survival Rates by fare")
ticket.party.size <- rep(0, nrow(data_combined))
avg.fare <- rep(0.0, nrow(data_combined))
tickets <- unique(data_combined$ticket)
for (i in 1:length(tickets)) {
current.ticket <- tickets[i]
party.indexes <- which(data_combined$ticket == current.ticket)
current.avg.fare <- data_combined[party.indexes[1], "fare"] / length(party.indexes)
for (k in 1:length(party.indexes)) {
ticket.party.size[party.indexes[k]] <- length(party.indexes)
avg.fare[party.indexes[k]] <- current.avg.fare
}
}
data_combined$ticket.party.size <- ticket.party.size
data_combined$avg.fare <- avg.fare
# Refresh 1st class "Mr." dataframe
first.mr.df <- data_combined[indexes.first.mr, ]
summary(first.mr.df)
# Visualize new features
ggplot(first.mr.df[first.mr.df$survived != "None",], aes(x = ticket.party.size, fill = survived)) +
geom_density(alpha = 0.5) +
ggtitle("Survival Rates 1st Class 'Mr.' by ticket.party.size")
ggplot(first.mr.df[first.mr.df$survived != "None",], aes(x = avg.fare, fill = survived)) +
geom_density(alpha = 0.5) +
ggtitle("Survival Rates 1st Class 'Mr.' by avg.fare")
